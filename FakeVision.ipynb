import os, glob
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor
from typing import Tuple

from PIL import Image, ImageChops, ImageEnhance
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision import models
from sklearn.model_selection import train_test_split

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

---------------------------------------------------------------------------------------------------------------------

def convert_to_ela_image(path: str, quality: int = 90) -> Image.Image:
    original = Image.open(path).convert("RGB")
    buffer = BytesIO()
    original.save(buffer, format="JPEG", quality=quality)
    buffer.seek(0)
    recompressed = Image.open(buffer).convert("RGB")
    ela_image = ImageChops.difference(original, recompressed)
    extrema = ela_image.getextrema()
    if isinstance(extrema[0], tuple):
        max_diff = max(channel[1] for channel in extrema)
    else:
        max_diff = extrema[1]
    scale = 255.0 / max_diff if max_diff != 0 else 1.0
    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)
    return ela_image

class ImageDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None, use_ela=False):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        self.use_ela = use_ela

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        path = self.image_paths[idx]
        label = int(self.labels[idx])
        if self.use_ela:
            img = convert_to_ela_image(path)
        else:
            img = Image.open(path).convert("RGB")
        if self.transform:
            img = self.transform(img)
        return img, label
---------------------------------------------------------------------------------------------------------------------

def make_resnet18_binary(pretrained=True):
    model = models.resnet18(pretrained=pretrained)
    in_features = model.fc.in_features
    model.fc = nn.Linear(in_features, 2)
    return model

def train_binary_model(model, train_loader, val_loader, epochs=5, lr=1e-4):
    model = model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for imgs, labels in train_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_loss = total_loss / len(train_loader)
        print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")

        # Evaluate at each epoch
        evaluate_binary_model(model, val_loader)

def evaluate_binary_model(model, loader):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    acc = 100.0 * correct / total
    print(f"Validation Accuracy: {acc:.2f}% ({correct}/{total})")
    return acc

---------------------------------------------------------------------------------------------------------------------

DATA_ROOT = r"C:\Users\Dell\OneDrive\Desktop\FakeVision++\archive"
REAL_DIR = os.path.join(DATA_ROOT, "real")
AI_DIR = os.path.join(DATA_ROOT, "ai_fake")
TAMPER_DIR = os.path.join(DATA_ROOT, "tampered")

real_imgs = glob.glob(os.path.join(REAL_DIR, "*.jpg"))[:500]
ai_imgs = glob.glob(os.path.join(AI_DIR, "*.jpg"))[:500]
tamper_imgs = glob.glob(os.path.join(TAMPER_DIR, "*.jpg"))[:500]

print("Counts -> real:", len(real_imgs), "ai:", len(ai_imgs), "tampered:", len(tamper_imgs))

transform = transforms.Compose([
    transforms.Resize((256,256)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])
])

# Datasets for AI vs Real
imgs_ai = real_imgs + ai_imgs
labels_ai = [0]*len(real_imgs) + [1]*len(ai_imgs)
train_paths_ai, val_paths_ai, train_lab_ai, val_lab_ai = train_test_split(
    imgs_ai, labels_ai, test_size=0.2, random_state=42, stratify=labels_ai
)
train_loader_ai = DataLoader(ImageDataset(train_paths_ai, train_lab_ai, transform, use_ela=False), batch_size=16, shuffle=True)
val_loader_ai = DataLoader(ImageDataset(val_paths_ai, val_lab_ai, transform, use_ela=False), batch_size=16)

# Datasets for Tampered vs Real
imgs_t = real_imgs + tamper_imgs
labels_t = [0]*len(real_imgs) + [1]*len(tamper_imgs)
train_paths_t, val_paths_t, train_lab_t, val_lab_t = train_test_split(
    imgs_t, labels_t, test_size=0.2, random_state=42, stratify=labels_t
)
train_loader_t = DataLoader(ImageDataset(train_paths_t, train_lab_t, transform, use_ela=True), batch_size=16, shuffle=True)
val_loader_t = DataLoader(ImageDataset(val_paths_t, val_lab_t, transform, use_ela=True), batch_size=16)

---------------------------------------------------------------------------------------------------------------------

# Train AI detector
model_ai = make_resnet18_binary(pretrained=True)
print("\n--- Training AI Detector ---")
train_binary_model(model_ai, train_loader_ai, val_loader_ai, epochs=10)

# Train Tampered detector
model_tamper = make_resnet18_binary(pretrained=True)
print("\n--- Training Tampered Detector ---")
train_binary_model(model_tamper, train_loader_t, val_loader_t, epochs=10)

---------------------------------------------------------------------------------------------------------------------

def parallel_detection(image_path, model_ai, model_tamper, transform):
    raw = Image.open(image_path).convert("RGB")
    ela = convert_to_ela_image(image_path)

    raw_t = transform(raw).unsqueeze(0).to(device)
    ela_t = transform(ela).unsqueeze(0).to(device)

    results = {}
    def run_ai():
        with torch.no_grad():
            results['ai'] = model_ai(raw_t)
    def run_tamper():
        with torch.no_grad():
            results['tamper'] = model_tamper(ela_t)

    with ThreadPoolExecutor(max_workers=2) as ex:
        f1 = ex.submit(run_ai)
        f2 = ex.submit(run_tamper)
        f1.result(); f2.result()

    ai_pred = torch.argmax(results['ai'], 1).item()
    tamper_pred = torch.argmax(results['tamper'], 1).item()

    if ai_pred == 0 and tamper_pred == 0:
        final = "Real"
    elif ai_pred == 1 and tamper_pred == 0:
        final = "Fake-AI"
    elif ai_pred == 0 and tamper_pred == 1:
        final = "Fake-Tampered"
    else:
        final = "Fake-Both"

    return final

# Example test
print(parallel_detection(real_imgs[0], model_ai, model_tamper, transform))

---------------------------------------------------------------------------------------------------------------------

